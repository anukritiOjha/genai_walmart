{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e951e1",
   "metadata": {},
   "source": [
    "#Step 1: Install Required Libraries\n",
    "\n",
    "pip install openai\n",
    "pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "help(OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c2588e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! üßÆ\n",
      "\n",
      "1. **5 √ó 5 = 25**  \n",
      "Multiplying 5 by itself gives 25.\n",
      "\n",
      "2. **5 + 10 + 20 + 30 = 65**  \n",
      "Adding the numbers together:  \n",
      "\\( 5 + 10 = 15 \\)  \n",
      "\\( 15 + 20 = 35 \\)  \n",
      "\\( 35 + 30 = 65 \\)  \n",
      "\n",
      "So, the answer is **65**. üòä\n"
     ]
    }
   ],
   "source": [
    "query = '''What is 5*5? Also solve 5 + 10 + 20 + 30 =?'''\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",  # Specify the model you want to use\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"}, # <-- This is the system message that provides context to the model\n",
    "    {\"role\": \"user\", \"content\": query},  # <-- This is the user message for which the model will generate a response\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing the perfect companion for your little adventurer ‚Äî the ColorSplash Kids Backpack, priced at just ‚Çπ999. Designed with vibrant hues and playful patterns, this backpack effortlessly combines style and functionality. Crafted from durable, water-resistant fabric, it ensures all their essentials stay safe and dry, whether they‚Äôre off to school or embarking on a weekend escapade. \n",
      "\n",
      "Featuring a spacious main compartment and multiple pockets, it offers ample space for books, toys, and snacks. The adjustable, padded shoulder straps ensure a comfortable fit for growing children, while the easy-to-clean surface makes maintenance a breeze for busy parents. With a sturdy top handle, this backpack is perfect for grab-and-go convenience. Let your child express their personality and venture into new adventures with the dependable and delightful ColorSplash Kids Backpack.\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Load and Interact with GPT (OpenAI)\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "MODEL=\"gpt-4o\"\n",
    "\n",
    "api_key = \"\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "# Step 3: Use the OpenAI client to generate a response\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a short product description for a ‚Çπ999 kids backpack.\"}\n",
    "    ] )\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30720d83",
   "metadata": {},
   "source": [
    "1.\tWalmart-genai-prototype\n",
    "\n",
    "Project number: 742467560939 Project ID: walmart-genai-prototype \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c531c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"walmart-genai-prototype\" # Replace with your Google Cloud project ID\n",
    "location = \"global\"  # Replace with your desired location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install the OpenAI Python client library\n",
    "# pip install openai\n",
    "# Step 2: Import the OpenAI client library\n",
    "from openai import OpenAI\n",
    "# Step 3: Initialize the OpenAI client with your API key\n",
    "api_key = \"your-openai-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with GCP beforehand (gcloud login)\n",
    "\n",
    "chat_model = ChatModel.from_pretrained(\"chat-bison\")\n",
    "\n",
    "chat = chat_model.start_chat()\n",
    "\n",
    "response = chat.send_message(\"Write a short product description for a ‚Çπ999 kids backpack.\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c368194",
   "metadata": {},
   "source": [
    "Step 1: Install Required SDK\n",
    "In your terminal:\n",
    "pip install --upgrade google-generativeai\n",
    "This installs the official Gemini Python SDK: google-generativeai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7550a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975e6edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Code Example ‚Äî walmart_gemini_demo.py\n",
    "\n",
    "# Step 1: Import required libraries\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a913a2",
   "metadata": {},
   "source": [
    "You import:\n",
    "‚Ä¢\tgenai to access Gemini models\n",
    "‚Ä¢\ttypes to build prompts and configs\n",
    "‚Ä¢\tvertexai to initialize the cloud environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94bba279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the Vertex AI environment\n",
    "vertexai.init(project=\"walmart-genai-prototype\", location=\"global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7defe",
   "metadata": {},
   "source": [
    "‚úÖ This tells Google Gemini which project and location you‚Äôre working in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775acab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Set up Gemini client\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"walmart-genai-prototype\",\n",
    "    location=\"global\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0957c7",
   "metadata": {},
   "source": [
    "‚úÖ This connects your code to Google‚Äôs Gemini model hosted on Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6bef3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Choose the model (Gemini 2.5 Flash is fast and smart)\n",
    "model = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54904ff0",
   "metadata": {},
   "source": [
    "‚úÖ You select a lightweight, fast Gemini model suitable for chat and content generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4247b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the user input as a message\n",
    "\n",
    "contents = [\n",
    "    types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "            types.Part.from_text(text='''Suggest 5 AI-powered business ideas for Walmart.''')\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a9ff9",
   "metadata": {},
   "source": [
    "‚úÖ You define what the user is asking ‚Äî here, a simple request for business ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "322fa821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Configure model output settings\n",
    "\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "    temperature=0.8,  # creativity\n",
    "    top_p=1,\n",
    "    max_output_tokens=1024  # output length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb8db2",
   "metadata": {},
   "source": [
    "‚úÖ You control how creative and how long the model‚Äôs response should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8adf83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Logistics & Returns Hub:** Cost savings, speed, potential for external service.\n",
      "    4.  **AI-Powered In-Store Experience & Security (Smart Store Ops):** Improves efficiency, reduces shrink, enhances safety.\n",
      "    5.  **Predictive Inventory & Dynamic MerWalmart\n",
      ", with its vast physical footprint, massive customer base, and extensive supply chain, is\n",
      " incredibly well-positioned to leverage AI for significant business growth and efficiency. Here are 5 AI\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Send the request and stream the response\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=model,\n",
    "    contents=contents,\n",
    "    config=generate_content_config,\n",
    "):\n",
    "    print(chunk.text, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586fe6a4",
   "metadata": {},
   "source": [
    "‚úÖ This sends the request to Gemini and prints the streamed response in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf647c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some possible names for a flower shop specializing in dried flower bouquets, broken down by style and feeling:\n",
      "\n",
      "**1. Evoking Longevity & Permanence:**\n",
      "*   **Everbloom & Co.**\n",
      "*   **Timeless Petals**\n",
      "*   **The Eternal Bloom**\n",
      "*   **Forever Flora**\n",
      "*   **Lasting Botanicals**\n",
      "*   **Preserved Petals**\n",
      "*   **Enduring Blooms**\n",
      "*   **The Unfading Bud**\n",
      "\n",
      "**2. Highlighting Natural Beauty & Texture:**\n",
      "*   **The Dried Stem**\n",
      "*   **Sun-Kissed Stems**\n",
      "*   **Air-Dried Botanicals**\n",
      "*   **Whispering Stems**\n",
      "*   **Russet & Rye** (referencing earthy tones and textures)\n",
      "*   **The Withered Bloom Co.** (a bit more direct, but can be artful)\n",
      "*   **Parchment & Petal**\n",
      "*   **Earthy Blooms**\n",
      "\n",
      "**3. Chic & Sophisticated:**\n",
      "*   **The Dried Bloom Atelier**\n",
      "*   **Still Life Florals**\n",
      "*   **Curated Botanics**\n",
      "*   **The Preserved Collection**\n",
      "*   **Aura Flora**\n",
      "*   **The Botanical Keepsake**\n",
      "*   **The Gathered Aesthetic**\n",
      "*   **Petal & Patina**\n",
      "\n",
      "**4. Whimsical & Charming:**\n",
      "*   **Petal & Twine**\n",
      "*   **The Fading Bloom**\n",
      "*   **Dusty Rose Florals**\n",
      "*   **The Herbal Hideaway**\n",
      "*   **Bloom & Basket**\n",
      "*   **Hearth & Bloom**\n",
      "*   **The Quiet Garden**\n",
      "*   **Folk Flora**\n",
      "\n",
      "**5. Direct & Descriptive:**\n",
      "*   **The Dried Flower Shop**\n",
      "*   **Dried & True Blooms**\n",
      "*   **Bouquets That Last**\n",
      "*   **Your Everlasting Bouquet**\n",
      "*   **Dried Flower Delights**\n",
      "\n",
      "**Tips for Choosing:**\n",
      "\n",
      "*   **Check availability:** Is the name available as a domain name, social media handle, and business registration?\n",
      "*   **Target Audience:** Who are you trying to attract? A sophisticated name for high-end clients, or something more casual for a broader appeal?\n",
      "*   **Memorability:** Is it easy to remember and say?\n",
      "*   **Brand Identity:** Does the name convey the feeling and style of your bouquets and your shop?\n",
      "*   **Test it out:** Say it out loud. Get feedback from friends or potential customers."
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import base64\n",
    "\n",
    "def generate():\n",
    "  client = genai.Client(\n",
    "      vertexai=True,\n",
    "      project=\"walmart-genai-prototype\",\n",
    "      location=\"global\",\n",
    "  )\n",
    "\n",
    "  model = \"gemini-2.5-flash\"\n",
    "  contents = [\n",
    "    types.Content(\n",
    "      role=\"user\",\n",
    "      parts=[\n",
    "        types.Part.from_text(text=\"\"\"What are some possible names for a flower shop that sells bouquets of dried flowers?.\"\"\")\n",
    "      ]\n",
    "    ),\n",
    "  ]\n",
    "\n",
    "  generate_content_config = types.GenerateContentConfig(\n",
    "    temperature = 1,\n",
    "    top_p = 1,\n",
    "    seed = 0,\n",
    "    max_output_tokens = 65535,\n",
    "    safety_settings = [types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "      threshold=\"OFF\"\n",
    "    )],\n",
    "    thinking_config=types.ThinkingConfig(\n",
    "      thinking_budget=-1,\n",
    "    ),\n",
    "  )\n",
    "\n",
    "  for chunk in client.models.generate_content_stream(\n",
    "    model = model,\n",
    "    contents = contents,\n",
    "    config = generate_content_config,\n",
    "    ):\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "666557ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting walmart_gemini_token_walkthrough.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile walmart_gemini_token_walkthrough.py\n",
    "\n",
    "# Step 1: Import required modules\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import vertexai\n",
    "\n",
    "# Step 2: Initialize Google Cloud Vertex AI\n",
    "vertexai.init(project=\"walmart-genai-prototype\", location=\"global\")\n",
    "\n",
    "# Step 3: Set up Gemini client\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"walmart-genai-prototype\",\n",
    "    location=\"global\"\n",
    ")\n",
    "\n",
    "# Step 4: Choose a fast and efficient model\n",
    "model = \"gemini-2.5-flash\"\n",
    "\n",
    "# Step 5: Define prompt variants\n",
    "prompts = [\n",
    "    \"List 5 new AI use cases for Walmart stores.\",\n",
    "    \"Can you suggest creative ways Walmart can use AI in stores?\",\n",
    "    \"Generate innovative AI-powered retail solutions for Walmart.\",\n",
    "]\n",
    "\n",
    "# Step 6: Model config\n",
    "config = types.GenerateContentConfig(\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    max_output_tokens=512,\n",
    ")\n",
    "\n",
    "# Step 7: Iterate through prompts and compare outputs\n",
    "for i, prompt in enumerate(prompts, start=1):\n",
    "    print(f\"\\nüîπ Prompt Style {i}: {prompt}\")\n",
    "\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part.from_text(text=prompt)]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=config,\n",
    "    ):\n",
    "        print(chunk.text, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83f3561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Prompt Style 1: List 5 new AI use cases for Walmart stores.\n",
      "\n",
      " Personalized Shopping Assistants & In-Store Navigation.\" This could involve AR, chatbots, or smart carts. Emphasize *personalHere are 5 new AI use cases for Walmart stores, focusing on enhancing customer experience, operational efficiency, and\n",
      "üîπ Prompt Style 2: Can you suggest creative ways Walmart can use AI in stores?\n",
      "\n",
      "alert system).\n",
      "        *   Spoilage -> CV (freshness detection), ML (predictive spoilage).\n",
      "    *   *Staffing:*\n",
      "        This is a fantastic question! Walmart, with its massive physical footprint and diverse customer base,None\n",
      "üîπ Prompt Style 3: Generate innovative AI-powered retail solutions for Walmart.\n",
      "\n",
      "vious:**\n",
      "    *   **Instead of \"better recommendations,\"** how about *proWalmart, with its vast physical footprint, massive e-commerce presence, and complex supply chain, is uniquely"
     ]
    }
   ],
   "source": [
    "!python3 walmart_gemini_token_walkthrough.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca004937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîπ Prompt Style 1\n",
      "üìù Prompt: List 5 new AI use cases for Walmart stores.\n",
      "ü§ñ Model: gemini-2.5-flash\n",
      "üì§ AI Response:\n",
      "\n",
      "            *   *Benefit:* Reduces out-of-stocks, improves planogram compliance, reduces waste, fasterHere are 5 new AI use cases for Walmart stores, focusing on cutting-edge applications that go beyond current\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üîπ Prompt Style 2\n",
      "üìù Prompt: Can you suggest creative ways Walmart can use AI in stores?\n",
      "ü§ñ Model: gemini-2.5-flash\n",
      "üì§ AI Response:\n",
      "\n",
      "Recommendations:* Personalized displays (predictive AI), interactive kiosks (genThis is a fantastic challenge! Walmart's scale and diverse customer base offer immense opportunities for AI.\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üîπ Prompt Style 3\n",
      "üìù Prompt: Generate innovative AI-powered retail solutions for Walmart.\n",
      "ü§ñ Model: gemini-2.5-flash\n",
      "üì§ AI Response:\n",
      "\n",
      "   *Innovation:* What if it knows *more*? LifestyleWalmart, with its vast scale, diverse customer base, and integrated physical and online presence, is\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import vertexai\n",
    "\n",
    "# Step 1: Initialize Google Cloud Vertex AI\n",
    "vertexai.init(project=\"walmart-genai-prototype\", location=\"global\")\n",
    "\n",
    "# Step 2: Setup Gemini client\n",
    "client = genai.Client(vertexai=True, project=\"walmart-genai-prototype\", location=\"global\")\n",
    "model = \"gemini-2.5-flash\"\n",
    "\n",
    "# Step 3: Define prompt variations\n",
    "prompts = [\n",
    "    \"List 5 new AI use cases for Walmart stores.\",\n",
    "    \"Can you suggest creative ways Walmart can use AI in stores?\",\n",
    "    \"Generate innovative AI-powered retail solutions for Walmart.\",\n",
    "]\n",
    "\n",
    "# Step 4: Define generation config\n",
    "config = types.GenerateContentConfig(\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    max_output_tokens=512,\n",
    ")\n",
    "\n",
    "# Step 5: Loop through each prompt and display result\n",
    "for i, prompt in enumerate(prompts, start=1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"üîπ Prompt Style {i}\")\n",
    "    print(f\"üìù Prompt: {prompt}\")\n",
    "    print(f\"ü§ñ Model: {model}\")\n",
    "    print(\"üì§ AI Response:\")\n",
    "\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part.from_text(text=prompt)]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=config,\n",
    "    ):\n",
    "        print(chunk.text, end=\"\")  # Stream and print each chunk\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70800a87",
   "metadata": {},
   "source": [
    "Prerequisites\n",
    "\t1.\tYou‚Äôve deployed GPT-4o on Azure OpenAI Studio.\n",
    "\t2.\tYou have the following info:\n",
    "\t‚Ä¢\tAZURE_OPENAI_API_KEY\n",
    "\t‚Ä¢\tAZURE_OPENAI_ENDPOINT (e.g., https://<your-resource-name>.openai.azure.com/)\n",
    "\t‚Ä¢\tAZURE_OPENAI_DEPLOYMENT_NAME (e.g., gpt-4o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd75e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between **AI (Artificial Intelligence)** and **AGI (Artificial General Intelligence)** lies in their scope, capabilities, and levels of intelligence.\n",
      "\n",
      "### **AI (Artificial Intelligence)**\n",
      "- **Definition**: AI refers to systems or algorithms designed to mimic human-like behaviors and solve specific tasks using data, machine learning, and pattern recognition. It is often narrow and specialized in scope.\n",
      "- **Capabilities**: AI is typically *narrow* intelligence, meaning it excels at specific, predetermined tasks, such as image recognition, natural language processing, or playing games like chess. For instance, AI can recommend products on e-commerce platforms or predict weather patterns, but it cannot apply its knowledge across multiple domains.\n",
      "- **Examples**: \n",
      "  - Speech recognition (e.g., Siri, Alexa)\n",
      "  - Machine vision (e.g., facial recognition)\n",
      "  - Recommendation systems (e.g., Netflix, Spotify)\n",
      "  - Autonomous driving (e.g., Tesla autopilot)\n",
      "- **Goal**: To solve specific problems efficiently, often without understanding the broader context of human experience or general intelligence.\n",
      "\n",
      "---\n",
      "\n",
      "### **AGI (Artificial General Intelligence)**\n",
      "- **Definition**: AGI refers to systems or algorithms that possess the ability to perform *any intellectual task* that a human is capable of. It involves general-purpose intelligence and the ability to learn and adapt across various domains with flexibility.\n",
      "- **Capabilities**: AGI is a level of intelligence that is *general*‚Äîit can understand, reason, and apply knowledge to unfamiliar tasks and domains in a human-like way. AGI would exhibit creativity, abstract reasoning, and the ability to learn new skills independently.\n",
      "- **Examples** (Hypothetical as of now): AGI might be able to simultaneously excel in scientific research, art creation, communication, problem-solving, and more without being specialized in just one task. No current AI system has achieved AGI yet.\n",
      "- **Goal**: To emulate human-level intelligence across all domains, eventually matching or surpassing human cognitive abilities.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Differences**\n",
      "| **Aspect**                   | **AI (Artificial Intelligence)**                    | **AGI (Artificial General Intelligence)**           |\n",
      "|-------------------------------|-----------------------------------------------------|-----------------------------------------------------|\n",
      "| **Scope**                    | Narrow intelligence, task-specific                  | General intelligence, adaptable to any domain       |\n",
      "| **Capabilities**             | Solves specific problems (e.g., diagnosing diseases)| Mimics human-like, flexible reasoning across tasks  |\n",
      "| **Examples**                 | Siri, ChatGPT (2023), self-driving cars             | Hypothetical systems (not yet achieved)            |\n",
      "| **Learning**                 | Limited self-learning, often domain-specific        | Broad, autonomous learning across diverse areas     |\n",
      "| **Human Comparison**         | Significant limits compared to human intelligence   | Comparable to or potentially greater than humans    |\n",
      "\n",
      "### Current State:\n",
      "While AI has made significant progress in specific areas, **AGI remains a theoretical concept**. Researchers are still working to develop AGI, and it may take decades (if it is even possible) to achieve such a level of intelligence.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set credentials\n",
    "api_base=\"https://azure-base/\"\n",
    "api_key=\"\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=api_base,\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")\n",
    "\n",
    "#  Simple chat completion request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the difference between AI and AGI?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de2317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**, and the square root of 144 is **12**.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Initialize the AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=\"\",  # Replace with your real key\n",
    "    api_version=\"2024-12-01-preview\",      # Required for GPT-4o\n",
    "    azure_endpoint=\"https://azure-openai/\",  # No trailing slash!\n",
    ")\n",
    "\n",
    "# Your deployment name (as configured in Azure portal)\n",
    "deployment_name = \"gpt-4o\"  # MUST match exactly\n",
    "\n",
    "# Make a chat completion call\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of France and the square root of 144?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36910b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's solve these:\n",
      "\n",
      "1. **5 √ó 5 = 25**\n",
      "\n",
      "2. **5 + 10 + 20 + 30 = 65**\n",
      "\n",
      "Final answers:  \n",
      "- 5 √ó 5 = **25**  \n",
      "- 5 + 10 + 20 + 30 = **65**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://azure-openai\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")\n",
    "\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")\n",
    "\n",
    "query = '''What is 5*5? Also solve 5 + 10 + 20 + 30 =?'''\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",  # Specify the model you want to use\n",
    "  # The model can be \"gpt-4o\", \"gpt-4o\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"}, # <-- This is the system message that provides context to the model\n",
    "    {\"role\": \"user\", \"content\": query},  # <-- This is the user message for which the model will generate a response\n",
    "  ],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45cb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a413428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Keep your little adventurer stylish and organized with our adorable kids' backpack, perfect for school and play! Designed for comfort and convenience, this ‚Çπ999 backpack features a lightweight yet durable build, spacious compartments, and adjustable padded straps for all-day ease. Eye-catching designs and vibrant colors make it fun for kids while ensuring practicality for parents. Ideal for books, lunch, or toys‚Äîthis backpack is a must-have for your child‚Äôs daily adventures!\"\n"
     ]
    }
   ],
   "source": [
    "#client = OpenAI(api_key=openai.api_key)\n",
    "# Step 3: Use the OpenAI client to generate a response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a short product description for a ‚Çπ999 kids backpack.\"}\n",
    "    ] )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import ssl\n",
    "headers = {\n",
    "    \"X-Api-Key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "context = ssl.create_default_context()\n",
    "context.load_verify_locations(\"ca-bundle.crt\")\n",
    "client = httpx.Client(verify=context, headers=headers)\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# If you are using ServiceRegistry - adjust the headers accordingly\n",
    "\n",
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=\"<ignored>\",\n",
    "    http_client=client,\n",
    "    azure_endpoint='https://wmtllmgateway.stage.walmart.com/wmtllmgateway',\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    api_version='2024-10-21'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
