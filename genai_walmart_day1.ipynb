{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e951e1",
   "metadata": {},
   "source": [
    "#Step 1: Install Required Libraries\n",
    "\n",
    "pip install openai\n",
    "pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "help(OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c2588e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! 🧮\n",
      "\n",
      "1. **5 × 5 = 25**  \n",
      "Multiplying 5 by itself gives 25.\n",
      "\n",
      "2. **5 + 10 + 20 + 30 = 65**  \n",
      "Adding the numbers together:  \n",
      "\\( 5 + 10 = 15 \\)  \n",
      "\\( 15 + 20 = 35 \\)  \n",
      "\\( 35 + 30 = 65 \\)  \n",
      "\n",
      "So, the answer is **65**. 😊\n"
     ]
    }
   ],
   "source": [
    "query = '''What is 5*5? Also solve 5 + 10 + 20 + 30 =?'''\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",  # Specify the model you want to use\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"}, # <-- This is the system message that provides context to the model\n",
    "    {\"role\": \"user\", \"content\": query},  # <-- This is the user message for which the model will generate a response\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing the perfect companion for your little adventurer — the ColorSplash Kids Backpack, priced at just ₹999. Designed with vibrant hues and playful patterns, this backpack effortlessly combines style and functionality. Crafted from durable, water-resistant fabric, it ensures all their essentials stay safe and dry, whether they’re off to school or embarking on a weekend escapade. \n",
      "\n",
      "Featuring a spacious main compartment and multiple pockets, it offers ample space for books, toys, and snacks. The adjustable, padded shoulder straps ensure a comfortable fit for growing children, while the easy-to-clean surface makes maintenance a breeze for busy parents. With a sturdy top handle, this backpack is perfect for grab-and-go convenience. Let your child express their personality and venture into new adventures with the dependable and delightful ColorSplash Kids Backpack.\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Load and Interact with GPT (OpenAI)\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "MODEL=\"gpt-4o\"\n",
    "\n",
    "api_key = \"\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "# Step 3: Use the OpenAI client to generate a response\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a short product description for a ₹999 kids backpack.\"}\n",
    "    ] )\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30720d83",
   "metadata": {},
   "source": [
    "1.\tWalmart-genai-prototype\n",
    "\n",
    "Project number: 742467560939 Project ID: walmart-genai-prototype \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c531c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"walmart-genai-prototype\" # Replace with your Google Cloud project ID\n",
    "location = \"global\"  # Replace with your desired location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install the OpenAI Python client library\n",
    "# pip install openai\n",
    "# Step 2: Import the OpenAI client library\n",
    "from openai import OpenAI\n",
    "# Step 3: Initialize the OpenAI client with your API key\n",
    "api_key = \"your-openai-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with GCP beforehand (gcloud login)\n",
    "\n",
    "chat_model = ChatModel.from_pretrained(\"chat-bison\")\n",
    "\n",
    "chat = chat_model.start_chat()\n",
    "\n",
    "response = chat.send_message(\"Write a short product description for a ₹999 kids backpack.\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c368194",
   "metadata": {},
   "source": [
    "Step 1: Install Required SDK\n",
    "In your terminal:\n",
    "pip install --upgrade google-generativeai\n",
    "This installs the official Gemini Python SDK: google-generativeai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7550a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975e6edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Code Example — walmart_gemini_demo.py\n",
    "\n",
    "# Step 1: Import required libraries\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a913a2",
   "metadata": {},
   "source": [
    "You import:\n",
    "•\tgenai to access Gemini models\n",
    "•\ttypes to build prompts and configs\n",
    "•\tvertexai to initialize the cloud environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94bba279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the Vertex AI environment\n",
    "vertexai.init(project=\"walmart-genai-prototype\", location=\"global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7defe",
   "metadata": {},
   "source": [
    "✅ This tells Google Gemini which project and location you’re working in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775acab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Set up Gemini client\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"walmart-genai-prototype\",\n",
    "    location=\"global\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0957c7",
   "metadata": {},
   "source": [
    "✅ This connects your code to Google’s Gemini model hosted on Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6bef3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Choose the model (Gemini 2.5 Flash is fast and smart)\n",
    "model = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54904ff0",
   "metadata": {},
   "source": [
    "✅ You select a lightweight, fast Gemini model suitable for chat and content generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4247b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the user input as a message\n",
    "\n",
    "contents = [\n",
    "    types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "            types.Part.from_text(text='''Suggest 5 AI-powered business ideas for Walmart.''')\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a9ff9",
   "metadata": {},
   "source": [
    "✅ You define what the user is asking — here, a simple request for business ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "322fa821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Configure model output settings\n",
    "\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "    temperature=0.8,  # creativity\n",
    "    top_p=1,\n",
    "    max_output_tokens=1024  # output length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb8db2",
   "metadata": {},
   "source": [
    "✅ You control how creative and how long the model’s response should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8adf83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Logistics & Returns Hub:** Cost savings, speed, potential for external service.\n",
      "    4.  **AI-Powered In-Store Experience & Security (Smart Store Ops):** Improves efficiency, reduces shrink, enhances safety.\n",
      "    5.  **Predictive Inventory & Dynamic MerWalmart\n",
      ", with its vast physical footprint, massive customer base, and extensive supply chain, is\n",
      " incredibly well-positioned to leverage AI for significant business growth and efficiency. Here are 5 AI\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Send the request and stream the response\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=model,\n",
    "    contents=contents,\n",
    "    config=generate_content_config,\n",
    "):\n",
    "    print(chunk.text, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586fe6a4",
   "metadata": {},
   "source": [
    "✅ This sends the request to Gemini and prints the streamed response in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf647c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some possible names for a flower shop specializing in dried flower bouquets, broken down by style and feeling:\n",
      "\n",
      "**1. Evoking Longevity & Permanence:**\n",
      "*   **Everbloom & Co.**\n",
      "*   **Timeless Petals**\n",
      "*   **The Eternal Bloom**\n",
      "*   **Forever Flora**\n",
      "*   **Lasting Botanicals**\n",
      "*   **Preserved Petals**\n",
      "*   **Enduring Blooms**\n",
      "*   **The Unfading Bud**\n",
      "\n",
      "**2. Highlighting Natural Beauty & Texture:**\n",
      "*   **The Dried Stem**\n",
      "*   **Sun-Kissed Stems**\n",
      "*   **Air-Dried Botanicals**\n",
      "*   **Whispering Stems**\n",
      "*   **Russet & Rye** (referencing earthy tones and textures)\n",
      "*   **The Withered Bloom Co.** (a bit more direct, but can be artful)\n",
      "*   **Parchment & Petal**\n",
      "*   **Earthy Blooms**\n",
      "\n",
      "**3. Chic & Sophisticated:**\n",
      "*   **The Dried Bloom Atelier**\n",
      "*   **Still Life Florals**\n",
      "*   **Curated Botanics**\n",
      "*   **The Preserved Collection**\n",
      "*   **Aura Flora**\n",
      "*   **The Botanical Keepsake**\n",
      "*   **The Gathered Aesthetic**\n",
      "*   **Petal & Patina**\n",
      "\n",
      "**4. Whimsical & Charming:**\n",
      "*   **Petal & Twine**\n",
      "*   **The Fading Bloom**\n",
      "*   **Dusty Rose Florals**\n",
      "*   **The Herbal Hideaway**\n",
      "*   **Bloom & Basket**\n",
      "*   **Hearth & Bloom**\n",
      "*   **The Quiet Garden**\n",
      "*   **Folk Flora**\n",
      "\n",
      "**5. Direct & Descriptive:**\n",
      "*   **The Dried Flower Shop**\n",
      "*   **Dried & True Blooms**\n",
      "*   **Bouquets That Last**\n",
      "*   **Your Everlasting Bouquet**\n",
      "*   **Dried Flower Delights**\n",
      "\n",
      "**Tips for Choosing:**\n",
      "\n",
      "*   **Check availability:** Is the name available as a domain name, social media handle, and business registration?\n",
      "*   **Target Audience:** Who are you trying to attract? A sophisticated name for high-end clients, or something more casual for a broader appeal?\n",
      "*   **Memorability:** Is it easy to remember and say?\n",
      "*   **Brand Identity:** Does the name convey the feeling and style of your bouquets and your shop?\n",
      "*   **Test it out:** Say it out loud. Get feedback from friends or potential customers."
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import base64\n",
    "\n",
    "def generate():\n",
    "  client = genai.Client(\n",
    "      vertexai=True,\n",
    "      project=\"walmart-genai-prototype\",\n",
    "      location=\"global\",\n",
    "  )\n",
    "\n",
    "  model = \"gemini-2.5-flash\"\n",
    "  contents = [\n",
    "    types.Content(\n",
    "      role=\"user\",\n",
    "      parts=[\n",
    "        types.Part.from_text(text=\"\"\"What are some possible names for a flower shop that sells bouquets of dried flowers?.\"\"\")\n",
    "      ]\n",
    "    ),\n",
    "  ]\n",
    "\n",
    "  generate_content_config = types.GenerateContentConfig(\n",
    "    temperature = 1,\n",
    "    top_p = 1,\n",
    "    seed = 0,\n",
    "    max_output_tokens = 65535,\n",
    "    safety_settings = [types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "      threshold=\"OFF\"\n",
    "    )],\n",
    "    thinking_config=types.ThinkingConfig(\n",
    "      thinking_budget=-1,\n",
    "    ),\n",
    "  )\n",
    "\n",
    "  for chunk in client.models.generate_content_stream(\n",
    "    model = model,\n",
    "    contents = contents,\n",
    "    config = generate_content_config,\n",
    "    ):\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "666557ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting walmart_gemini_token_walkthrough.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile walmart_gemini_token_walkthrough.py\n",
    "\n",
    "# Step 1: Import required modules\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import vertexai\n",
    "\n",
    "# Step 2: Initialize Google Cloud Vertex AI\n",
    "vertexai.init(project=\"walmart-genai-prototype\", location=\"global\")\n",
    "\n",
    "# Step 3: Set up Gemini client\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"walmart-genai-prototype\",\n",
    "    location=\"global\"\n",
    ")\n",
    "\n",
    "# Step 4: Choose a fast and efficient model\n",
    "model = \"gemini-2.5-flash\"\n",
    "\n",
    "# Step 5: Define prompt variants\n",
    "prompts = [\n",
    "    \"List 5 new AI use cases for Walmart stores.\",\n",
    "    \"Can you suggest creative ways Walmart can use AI in stores?\",\n",
    "    \"Generate innovative AI-powered retail solutions for Walmart.\",\n",
    "]\n",
    "\n",
    "# Step 6: Model config\n",
    "config = types.GenerateContentConfig(\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    max_output_tokens=512,\n",
    ")\n",
    "\n",
    "# Step 7: Iterate through prompts and compare outputs\n",
    "for i, prompt in enumerate(prompts, start=1):\n",
    "    print(f\"\\n🔹 Prompt Style {i}: {prompt}\")\n",
    "\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part.from_text(text=prompt)]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=config,\n",
    "    ):\n",
    "        print(chunk.text, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83f3561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Prompt Style 1: List 5 new AI use cases for Walmart stores.\n",
      "\n",
      " Personalized Shopping Assistants & In-Store Navigation.\" This could involve AR, chatbots, or smart carts. Emphasize *personalHere are 5 new AI use cases for Walmart stores, focusing on enhancing customer experience, operational efficiency, and\n",
      "🔹 Prompt Style 2: Can you suggest creative ways Walmart can use AI in stores?\n",
      "\n",
      "alert system).\n",
      "        *   Spoilage -> CV (freshness detection), ML (predictive spoilage).\n",
      "    *   *Staffing:*\n",
      "        This is a fantastic question! Walmart, with its massive physical footprint and diverse customer base,None\n",
      "🔹 Prompt Style 3: Generate innovative AI-powered retail solutions for Walmart.\n",
      "\n",
      "vious:**\n",
      "    *   **Instead of \"better recommendations,\"** how about *proWalmart, with its vast physical footprint, massive e-commerce presence, and complex supply chain, is uniquely"
     ]
    }
   ],
   "source": [
    "!python3 walmart_gemini_token_walkthrough.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca004937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🔹 Prompt Style 1\n",
      "📝 Prompt: List 5 new AI use cases for Walmart stores.\n",
      "🤖 Model: gemini-2.5-flash\n",
      "📤 AI Response:\n",
      "\n",
      "            *   *Benefit:* Reduces out-of-stocks, improves planogram compliance, reduces waste, fasterHere are 5 new AI use cases for Walmart stores, focusing on cutting-edge applications that go beyond current\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "🔹 Prompt Style 2\n",
      "📝 Prompt: Can you suggest creative ways Walmart can use AI in stores?\n",
      "🤖 Model: gemini-2.5-flash\n",
      "📤 AI Response:\n",
      "\n",
      "Recommendations:* Personalized displays (predictive AI), interactive kiosks (genThis is a fantastic challenge! Walmart's scale and diverse customer base offer immense opportunities for AI.\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "🔹 Prompt Style 3\n",
      "📝 Prompt: Generate innovative AI-powered retail solutions for Walmart.\n",
      "🤖 Model: gemini-2.5-flash\n",
      "📤 AI Response:\n",
      "\n",
      "   *Innovation:* What if it knows *more*? LifestyleWalmart, with its vast scale, diverse customer base, and integrated physical and online presence, is\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import vertexai\n",
    "\n",
    "# Step 1: Initialize Google Cloud Vertex AI\n",
    "vertexai.init(project=\"walmart-genai-prototype\", location=\"global\")\n",
    "\n",
    "# Step 2: Setup Gemini client\n",
    "client = genai.Client(vertexai=True, project=\"walmart-genai-prototype\", location=\"global\")\n",
    "model = \"gemini-2.5-flash\"\n",
    "\n",
    "# Step 3: Define prompt variations\n",
    "prompts = [\n",
    "    \"List 5 new AI use cases for Walmart stores.\",\n",
    "    \"Can you suggest creative ways Walmart can use AI in stores?\",\n",
    "    \"Generate innovative AI-powered retail solutions for Walmart.\",\n",
    "]\n",
    "\n",
    "# Step 4: Define generation config\n",
    "config = types.GenerateContentConfig(\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    max_output_tokens=512,\n",
    ")\n",
    "\n",
    "# Step 5: Loop through each prompt and display result\n",
    "for i, prompt in enumerate(prompts, start=1):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"🔹 Prompt Style {i}\")\n",
    "    print(f\"📝 Prompt: {prompt}\")\n",
    "    print(f\"🤖 Model: {model}\")\n",
    "    print(\"📤 AI Response:\")\n",
    "\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part.from_text(text=prompt)]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=config,\n",
    "    ):\n",
    "        print(chunk.text, end=\"\")  # Stream and print each chunk\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70800a87",
   "metadata": {},
   "source": [
    "Prerequisites\n",
    "\t1.\tYou’ve deployed GPT-4o on Azure OpenAI Studio.\n",
    "\t2.\tYou have the following info:\n",
    "\t•\tAZURE_OPENAI_API_KEY\n",
    "\t•\tAZURE_OPENAI_ENDPOINT (e.g., https://<your-resource-name>.openai.azure.com/)\n",
    "\t•\tAZURE_OPENAI_DEPLOYMENT_NAME (e.g., gpt-4o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd75e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between **AI (Artificial Intelligence)** and **AGI (Artificial General Intelligence)** lies in their scope, capabilities, and levels of intelligence.\n",
      "\n",
      "### **AI (Artificial Intelligence)**\n",
      "- **Definition**: AI refers to systems or algorithms designed to mimic human-like behaviors and solve specific tasks using data, machine learning, and pattern recognition. It is often narrow and specialized in scope.\n",
      "- **Capabilities**: AI is typically *narrow* intelligence, meaning it excels at specific, predetermined tasks, such as image recognition, natural language processing, or playing games like chess. For instance, AI can recommend products on e-commerce platforms or predict weather patterns, but it cannot apply its knowledge across multiple domains.\n",
      "- **Examples**: \n",
      "  - Speech recognition (e.g., Siri, Alexa)\n",
      "  - Machine vision (e.g., facial recognition)\n",
      "  - Recommendation systems (e.g., Netflix, Spotify)\n",
      "  - Autonomous driving (e.g., Tesla autopilot)\n",
      "- **Goal**: To solve specific problems efficiently, often without understanding the broader context of human experience or general intelligence.\n",
      "\n",
      "---\n",
      "\n",
      "### **AGI (Artificial General Intelligence)**\n",
      "- **Definition**: AGI refers to systems or algorithms that possess the ability to perform *any intellectual task* that a human is capable of. It involves general-purpose intelligence and the ability to learn and adapt across various domains with flexibility.\n",
      "- **Capabilities**: AGI is a level of intelligence that is *general*—it can understand, reason, and apply knowledge to unfamiliar tasks and domains in a human-like way. AGI would exhibit creativity, abstract reasoning, and the ability to learn new skills independently.\n",
      "- **Examples** (Hypothetical as of now): AGI might be able to simultaneously excel in scientific research, art creation, communication, problem-solving, and more without being specialized in just one task. No current AI system has achieved AGI yet.\n",
      "- **Goal**: To emulate human-level intelligence across all domains, eventually matching or surpassing human cognitive abilities.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Differences**\n",
      "| **Aspect**                   | **AI (Artificial Intelligence)**                    | **AGI (Artificial General Intelligence)**           |\n",
      "|-------------------------------|-----------------------------------------------------|-----------------------------------------------------|\n",
      "| **Scope**                    | Narrow intelligence, task-specific                  | General intelligence, adaptable to any domain       |\n",
      "| **Capabilities**             | Solves specific problems (e.g., diagnosing diseases)| Mimics human-like, flexible reasoning across tasks  |\n",
      "| **Examples**                 | Siri, ChatGPT (2023), self-driving cars             | Hypothetical systems (not yet achieved)            |\n",
      "| **Learning**                 | Limited self-learning, often domain-specific        | Broad, autonomous learning across diverse areas     |\n",
      "| **Human Comparison**         | Significant limits compared to human intelligence   | Comparable to or potentially greater than humans    |\n",
      "\n",
      "### Current State:\n",
      "While AI has made significant progress in specific areas, **AGI remains a theoretical concept**. Researchers are still working to develop AGI, and it may take decades (if it is even possible) to achieve such a level of intelligence.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set credentials\n",
    "api_base=\"https://azure-base/\"\n",
    "api_key=\"\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=api_base,\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")\n",
    "\n",
    "#  Simple chat completion request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the difference between AI and AGI?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de2317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**, and the square root of 144 is **12**.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Initialize the AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=\"\",  # Replace with your real key\n",
    "    api_version=\"2024-12-01-preview\",      # Required for GPT-4o\n",
    "    azure_endpoint=\"https://azure-openai/\",  # No trailing slash!\n",
    ")\n",
    "\n",
    "# Your deployment name (as configured in Azure portal)\n",
    "deployment_name = \"gpt-4o\"  # MUST match exactly\n",
    "\n",
    "# Make a chat completion call\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of France and the square root of 144?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36910b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's solve these:\n",
      "\n",
      "1. **5 × 5 = 25**\n",
      "\n",
      "2. **5 + 10 + 20 + 30 = 65**\n",
      "\n",
      "Final answers:  \n",
      "- 5 × 5 = **25**  \n",
      "- 5 + 10 + 20 + 30 = **65**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://azure-openai\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")\n",
    "\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")\n",
    "\n",
    "query = '''What is 5*5? Also solve 5 + 10 + 20 + 30 =?'''\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",  # Specify the model you want to use\n",
    "  # The model can be \"gpt-4o\", \"gpt-4o\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"}, # <-- This is the system message that provides context to the model\n",
    "    {\"role\": \"user\", \"content\": query},  # <-- This is the user message for which the model will generate a response\n",
    "  ],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45cb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a413428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Keep your little adventurer stylish and organized with our adorable kids' backpack, perfect for school and play! Designed for comfort and convenience, this ₹999 backpack features a lightweight yet durable build, spacious compartments, and adjustable padded straps for all-day ease. Eye-catching designs and vibrant colors make it fun for kids while ensuring practicality for parents. Ideal for books, lunch, or toys—this backpack is a must-have for your child’s daily adventures!\"\n"
     ]
    }
   ],
   "source": [
    "#client = OpenAI(api_key=openai.api_key)\n",
    "# Step 3: Use the OpenAI client to generate a response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a short product description for a ₹999 kids backpack.\"}\n",
    "    ] )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import ssl\n",
    "headers = {\n",
    "    \"X-Api-Key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "context = ssl.create_default_context()\n",
    "context.load_verify_locations(\"ca-bundle.crt\")\n",
    "client = httpx.Client(verify=context, headers=headers)\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# If you are using ServiceRegistry - adjust the headers accordingly\n",
    "\n",
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=\"<ignored>\",\n",
    "    http_client=client,\n",
    "    azure_endpoint='https://wmtllmgateway.stage.walmart.com/wmtllmgateway',\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    api_version='2024-10-21'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
